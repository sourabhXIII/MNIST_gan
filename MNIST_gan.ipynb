{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate MNIST digits using GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T18:01:25.939473Z",
     "start_time": "2019-07-03T18:01:25.935461Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "from keras import layers as L\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "print(K.tensorflow_backend._get_available_gpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T16:29:28.716361Z",
     "start_time": "2019-07-03T16:29:28.711347Z"
    }
   },
   "outputs": [],
   "source": [
    "# Some constants\n",
    "img_height = 64\n",
    "img_width = 64\n",
    "img_channels = 3\n",
    "img_shape = (img_height, img_width, img_channels)\n",
    "latent_dim = 250\n",
    "batch_size = 64\n",
    "n_epochs = 200\n",
    "img_path = r\"C:\\__MyComputer\\OneDrive - Teradata\\Drive_SM\\Course\\analyticsvidhya\\facecounting\\image_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T18:01:18.118612Z",
     "start_time": "2019-07-03T18:01:18.112596Z"
    },
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# save the generated images\n",
    "def sample_images(epoch):\n",
    "    r, c = 2, 2\n",
    "    noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "    gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "    # Rescale images\n",
    "    gen_imgs = ((gen_imgs+1)*127.5).astype(np.uint8)\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i,j].imshow(gen_imgs[cnt, :,:,0])\n",
    "            axs[i,j].axis('off')\n",
    "            cnt += 1\n",
    "    # fig.savefig(\"images/%d.png\" % epoch)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T17:10:42.008665Z",
     "start_time": "2019-07-03T17:10:42.005155Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "\n",
    "def perceptual_loss(y_true, y_pred):\n",
    "    vgg = VGG16(include_top=False, weights='imagenet', input_shape=img_shape)\n",
    "    loss_model = Model(inputs=vgg.input, outputs=vgg.get_layer('block3_conv3').output)\n",
    "    loss_model.trainable = False\n",
    "    return K.mean(K.square(loss_model(y_true) - loss_model(y_pred)))\n",
    "\n",
    "\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true*y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T16:32:15.232110Z",
     "start_time": "2019-07-03T16:32:15.223500Z"
    },
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# define the generator\n",
    "def build_generator():\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(L.Dense(256, input_dim=latent_dim))\n",
    "    model.add(L.advanced_activations.LeakyReLU(alpha=0.2))\n",
    "    model.add(L.BatchNormalization(momentum=0.8))\n",
    "    model.add(L.Dense(512))\n",
    "    model.add(L.advanced_activations.LeakyReLU(alpha=0.2))\n",
    "    model.add(L.BatchNormalization(momentum=0.8))\n",
    "    model.add(L.Dense(1024))\n",
    "    model.add(L.advanced_activations.LeakyReLU(alpha=0.2))\n",
    "    model.add(L.BatchNormalization(momentum=0.8))\n",
    "    # this layer will generate the image. it must have as many units as many pixels are there in the output image.\n",
    "    model.add(L.Dense(np.prod(img_shape), activation='tanh'))\n",
    "    # reshape as an image\n",
    "    model.add(L.Reshape(img_shape))\n",
    "    model.name = 'G'\n",
    "    model.summary()\n",
    "\n",
    "    noise = L.Input(shape=(latent_dim,))\n",
    "    img = model(noise)\n",
    "\n",
    "    return Model(noise, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T16:32:16.074472Z",
     "start_time": "2019-07-03T16:32:16.070461Z"
    },
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# define the discriminator\n",
    "def build_discriminator():\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(L.Flatten(input_shape=img_shape))\n",
    "    model.add(L.Dense(512))\n",
    "    model.add(L.advanced_activations.LeakyReLU(alpha=0.2))\n",
    "    model.add(L.Dense(256))\n",
    "    model.add(L.advanced_activations.LeakyReLU(alpha=0.2))\n",
    "    model.add(L.Dense(1, activation='sigmoid'))\n",
    "    model.name = 'D'\n",
    "    model.summary()\n",
    "\n",
    "    img = L.Input(shape=img_shape)\n",
    "    validity = model(img)\n",
    "\n",
    "    return Model(img, validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T17:10:17.320072Z",
     "start_time": "2019-07-03T17:10:17.316064Z"
    },
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "def generator_containing_discriminator(generator, discriminator):\n",
    "    inputs = L.Input(shape=(latent_dim,))\n",
    "    generated_image = generator(inputs)\n",
    "    outputs = discriminator(generated_image)\n",
    "    model = Model(inputs=inputs, outputs=outputs, name='DonG')\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "def generator_containing_discriminator_multiple_outputs(generator, discriminator):\n",
    "    inputs = L.Input(shape=(latent_dim,))\n",
    "    generated_image = generator(inputs)\n",
    "    outputs = discriminator(generated_image)\n",
    "    model = Model(inputs=inputs, outputs=[generated_image, outputs], name='DonGM')\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T17:11:36.010697Z",
     "start_time": "2019-07-03T17:11:35.997630Z"
    },
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "def train_multiple_outputs(log_dir=r'log', epoch_num=n_epochs, critic_updates=2):\n",
    "    print(\"Image path\", img_path)\n",
    "    datagen = ImageDataGenerator( \n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        shear_range=0.2\n",
    "        ).flow_from_directory(\n",
    "                img_path,\n",
    "                # '../input/all-dogs/',\n",
    "                target_size=(img_height, img_width),\n",
    "                batch_size=64)\n",
    "    imgs, _ = next(datagen)\n",
    "    print(imgs.shape)\n",
    "    from keras.preprocessing import image\n",
    "    plt.imshow(image.array_to_img(imgs[3]))\n",
    "    plt.show()\n",
    "\n",
    "    g = build_generator()\n",
    "    d = build_discriminator()\n",
    "    \n",
    "    d_on_g = generator_containing_discriminator_multiple_outputs(g, d)\n",
    "\n",
    "    d_opt = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    d_on_g_opt = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "    d.trainable = True\n",
    "    d.compile(optimizer=d_opt, loss=wasserstein_loss)\n",
    "    d.trainable = False\n",
    "    loss = [perceptual_loss, wasserstein_loss]\n",
    "    loss_weights = [100, 1]\n",
    "    d_on_g.compile(optimizer=d_on_g_opt, loss=loss, loss_weights=loss_weights)\n",
    "    d.trainable = True\n",
    "\n",
    "\n",
    "    for epoch in tqdm_notebook(range(epoch_num)):\n",
    "        d_losses = []\n",
    "        d_on_g_losses = []\n",
    "        for idx in tqdm_notebook(range(len(datagen)), total=len(datagen)):\n",
    "            batch_size = len(datagen[idx][0])\n",
    "            # Adversarial ground truths\n",
    "            output_true_batch = np.ones((batch_size, 1))\n",
    "            output_false_batch = np.zeros((batch_size, 1))\n",
    "            \n",
    "            # Select a batch of images\n",
    "            imgs = datagen[idx][0]\n",
    "            real_imgs = (imgs - 127.5) / 127.5\n",
    "\n",
    "            noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "\n",
    "            generated_images = g.predict(x=noise, batch_size=batch_size)\n",
    "\n",
    "            for _ in range(critic_updates):\n",
    "                d_loss_real = d.train_on_batch(real_imgs, output_true_batch)\n",
    "                d_loss_fake = d.train_on_batch(generated_images, output_false_batch)\n",
    "                d_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n",
    "                d_losses.append(d_loss)\n",
    "\n",
    "            d.trainable = False\n",
    "\n",
    "            d_on_g_loss = d_on_g.train_on_batch(noise, [real_imgs, output_true_batch])\n",
    "            d_on_g_losses.append(d_on_g_loss)\n",
    "\n",
    "            d.trainable = True\n",
    "\n",
    "        # write_log(tensorboard_callback, ['g_loss', 'd_on_g_loss'], [np.mean(d_losses), np.mean(d_on_g_losses)], epoch_num)\n",
    "        print(np.mean(d_losses), np.mean(d_on_g_losses))\n",
    "        # If at save interval => save generated image samples\n",
    "        if epoch % 10 == 0:\n",
    "            sample_images(epoch)\n",
    "            # save_all_weights(d, g, epoch, int(np.mean(d_on_g_losses)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-03T17:25:46.482632Z",
     "start_time": "2019-07-03T17:11:36.990985Z"
    }
   },
   "outputs": [],
   "source": [
    "train_multiple_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "nteract": {
   "version": "0.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
