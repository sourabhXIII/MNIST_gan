{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate MNIST digits using GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/job:localhost/replica:0/task:0/device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "from keras import layers as L\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Model, Sequential\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from keras import backend as K\n",
    "print(K.tensorflow_backend._get_available_gpus())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some constants\n",
    "img_height = 64\n",
    "img_width = 64\n",
    "img_channels = 3\n",
    "img_shape = (img_height, img_width, img_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "\n",
    "def perceptual_loss(y_true, y_pred):\n",
    "    vgg = VGG16(include_top=False, weights='imagenet', input_shape=image_shape)\n",
    "    loss_model = Model(inputs=vgg.input, outputs=vgg.get_layer('block3_conv3').output)\n",
    "    loss_model.trainable = False\n",
    "    return K.mean(K.square(loss_model(y_true) - loss_model(y_pred)))\n",
    "\n",
    "\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true*y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 64\n",
    "        self.img_cols = 64\n",
    "        self.channels = 3\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 200\n",
    "        self.batch_size = 64\n",
    "        \n",
    "        self.datagen = ImageDataGenerator( \n",
    "                featurewise_center=True,\n",
    "                featurewise_std_normalization=True,\n",
    "                rotation_range=20,\n",
    "                width_shift_range=0.2,\n",
    "                height_shift_range=0.2,\n",
    "                horizontal_flip=True,\n",
    "                shear_range=0.2\n",
    "            ).flow_from_directory(\n",
    "                    '../input/all-dogs/',\n",
    "                    target_size=(self.img_rows, self.img_cols),\n",
    "                    batch_size=self.batch_size)\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.9, 0.9, 1e-08)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss=wasserstein_loss,\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generates imgs\n",
    "        z = L.Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        validity = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, [img, validity])\n",
    "        self.combined.compile(loss=perceptual_loss, optimizer=optimizer)\n",
    "\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(L.Dense(256, input_dim=self.latent_dim))\n",
    "        model.add(L.advanced_activations.LeakyReLU(alpha=0.2))\n",
    "        model.add(L.BatchNormalization(momentum=0.8))\n",
    "        model.add(L.Dense(512))\n",
    "        model.add(L.advanced_activations.LeakyReLU(alpha=0.2))\n",
    "        model.add(L.BatchNormalization(momentum=0.8))\n",
    "        model.add(L.Dense(1024))\n",
    "        model.add(L.advanced_activations.LeakyReLU(alpha=0.2))\n",
    "        model.add(L.BatchNormalization(momentum=0.8))\n",
    "        model.add(L.Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(L.Reshape(self.img_shape))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = L.Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(L.Flatten(input_shape=self.img_shape))\n",
    "        model.add(L.Dense(512))\n",
    "        model.add(L.advanced_activations.LeakyReLU(alpha=0.2))\n",
    "        model.add(L.Dense(256))\n",
    "        model.add(L.advanced_activations.LeakyReLU(alpha=0.2))\n",
    "        model.add(L.Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        img = L.Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            for idx in tqdm_notebook(range(len(self.datagen)), total=len(self.datagen)):\n",
    "                batch_size = len(self.datagen[idx][0])\n",
    "                # Adversarial ground truths\n",
    "                valid = np.ones((batch_size, 1))\n",
    "                fake = np.zeros((batch_size, 1))\n",
    "                \n",
    "                # ---------------------\n",
    "                #  Train Discriminator\n",
    "                # ---------------------\n",
    "\n",
    "                # Select a batch of images\n",
    "                imgs = self.datagen[idx][0]\n",
    "                imgs = (imgs - 127.5) / 127.5\n",
    "\n",
    "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "                # Generate a batch of new images\n",
    "                gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "                # Train the discriminator\n",
    "                d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "                d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Generator\n",
    "                # ---------------------\n",
    "\n",
    "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "                # Train the generator (to have the discriminator label samples as valid)\n",
    "                g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % sample_interval == 0:\n",
    "                self.sample_images(epoch)\n",
    "\n",
    "    def sample_images(self, epoch):\n",
    "        r, c = 2, 2\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images\n",
    "        gen_imgs = ((gen_imgs+1)*127.5).astype(np.uint8)\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0])\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        # fig.savefig(\"images/%d.png\" % epoch)\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = GAN()\n",
    "imgs, _ = next(gan.datagen)\n",
    "print(imgs.shape)\n",
    "from keras.preprocessing import image\n",
    "plt.imshow(image.array_to_img(imgs[3]))\n",
    "plt.show()\n",
    "gan.train(epochs=250, batch_size=32, sample_interval=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
